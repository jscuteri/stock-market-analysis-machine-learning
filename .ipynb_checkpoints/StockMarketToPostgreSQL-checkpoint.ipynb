{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "\n",
    "file_root = \"Resources/\"\n",
    "target_table_name = \"etf_graphdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Columns:\n",
    "    \n",
    "    asset_id      = \"asset_id\"\n",
    "    future_x2050  = \"future_x2050\"\n",
    "    y_predict2050 = \"y_predict2050\"\n",
    "    y_predict     = \"y_predict\"\n",
    "    future_x      = \"future_x\"\n",
    "    y_learned     = \"y_learned\"\n",
    "    y             = \"y\"\n",
    "    xp            = \"Xp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data buckets for source of wealth and education\n",
    "\n",
    "class CsvFile:\n",
    "    \n",
    "    DIA_CSV_GraphData = \"DIA_CSV_GraphData.csv\" #1\n",
    "    IWM_CSV_GraphData = \"IWM_CSV_GraphData.csv\" #2\n",
    "    QQQ_CSV_GraphData = \"QQQ_CSV_GraphData.csv\" #3\n",
    "    SPY_CSV_GraphData = \"SPY_CSV_GraphData.csv\" #4\n",
    "    XLB_CSV_GraphData = \"XLB_CSV_GraphData.csv\" #5\n",
    "    XLE_CSV_GraphData = \"XLE_CSV_GraphData.csv\" #6\n",
    "    XLF_CSV_GraphData = \"XLF_CSV_GraphData.csv\" #7\n",
    "    XLI_CSV_GraphData = \"XLI_CSV_GraphData.csv\" #8\n",
    "    XLK_CSV_GraphData = \"XLK_CSV_GraphData.csv\" #9\n",
    "    XLP_CSV_GraphData = \"XLP_CSV_GraphData.csv\" #10\n",
    "    XLU_CSV_GraphData = \"XLU_CSV_GraphData.csv\" #11\n",
    "    XLV_CSV_GraphData = \"XLV_CSV_GraphData.csv\" #12\n",
    "    XLY_CSV_GraphData = \"XLY_CSV_GraphData.csv\" #13    \n",
    "\n",
    "    \n",
    "file_names = [CsvFile.DIA_CSV_GraphData, \\\n",
    "              CsvFile.IWM_CSV_GraphData, \\\n",
    "              CsvFile.QQQ_CSV_GraphData, \\\n",
    "              CsvFile.SPY_CSV_GraphData, \\\n",
    "              CsvFile.XLB_CSV_GraphData, \\\n",
    "              CsvFile.XLE_CSV_GraphData, \\\n",
    "              CsvFile.XLF_CSV_GraphData, \\\n",
    "              CsvFile.XLI_CSV_GraphData, \\\n",
    "              CsvFile.XLK_CSV_GraphData, \\\n",
    "              CsvFile.XLP_CSV_GraphData, \\\n",
    "              CsvFile.XLU_CSV_GraphData, \\\n",
    "              CsvFile.XLV_CSV_GraphData, \\\n",
    "              CsvFile.XLY_CSV_GraphData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_container = []\n",
    "\n",
    "password   =\"postgres\"\n",
    "engine     = create_engine(f'postgresql://postgres:{password}@localhost:5432/StockMarket')\n",
    "connection = engine.connect()\n",
    "\n",
    "for file_name in file_names:\n",
    "    \n",
    "    metadata_path = f\"{file_root}{file_name}\"\n",
    "    metadata      = pd.read_csv(metadata_path)\n",
    "    df            = pd.DataFrame(metadata).astype({Columns.asset_id:       str,\n",
    "                                                   Columns.future_x2050:   str,\n",
    "                                                   Columns.y_predict2050:  float,\n",
    "                                                   Columns.y_predict:      float,\n",
    "                                                   Columns.future_x:       str,\n",
    "                                                   Columns.y_learned:      float,\n",
    "                                                   Columns.y:              float,\n",
    "                                                   Columns.xp:             str})\n",
    "    \n",
    "    for i in range(50):\n",
    "        if f'Unnamed: {i}' in df.columns:\n",
    "            df.drop(axis=1, columns = f'Unnamed: {i}', inplace=True)\n",
    "    \n",
    "    df = df.rename(columns={Columns.xp:\"xp\"})\n",
    "    df.to_sql(name=target_table_name, con=engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
